---
title: "Collecting and mapping tweets in R"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: tango
---


```{r knitr_init, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE}
library(knitr)
library(rmdformats)
library(magrittr)
library(tidyverse)
## Global options
options(max.print = "75")
opts_chunk$set(eval = FALSE,
	             cache = FALSE,
               prompt = FALSE,
               tidy = FALSE,
               comment = NA,
               message = FALSE,
               warning = FALSE,
               size = "small")
opts_knit$set(width = 75)
# file time ----
file_time <- lubridate::now(tzone = "US/Pacific-New") %>% 
    as.character.Date() 
# what is the file title? ----
file_title <- c("collecting_tweets")
# what is the file version? ----
file_version <- c("2.4")
file_title <- stringr::str_to_lower(
    stringr::str_replace_all(file_title, "\\W", "_"))
file_name <- paste0(file_version,"-",file_title, ".Rmd")
# file_name ----
opts_knit$set(width = 75)
file_name

# numvarSum function ----------------------------------------------
# this summarizes a numerical variable (n, na(missing, mean, median, sd,
# variance, min, max, and se) when given a data frame or tibble and
# variable: q14_rpt_fun(df, var)

numvarSum <- function(df, expr) {
  expr <- enquo(expr) # turns expr into a quosure
  summarise(df,
          n = sum((!is.na(!!expr))), # non-missing
          na = sum((is.na(!!expr))), # missing
          mean = mean(!!expr, na.rm = TRUE), # unquotes mean()
          median = median(!!expr, na.rm = TRUE), # unquotes median()
          sd = sd(!!expr, na.rm = TRUE), # unquotes sd()
          variance = var(!!expr, na.rm = TRUE), # unquotes var()
          min = min(!!expr, na.rm = TRUE), # unquotes min()
          max = max(!!expr, na.rm = TRUE), # unquotes max()
          se = sd/sqrt(n)) # standard error
}
```

<!-- Load data -->

```{r tweet_searches_data_path, echo=FALSE, eval=TRUE}
tweet_searches_data_path <- "Data/tweet_searches/"
fs::dir_ls(tweet_searches_data_path) %>% writeLines()
DubNtnStrngthNmbrs <- read_rds(paste0(tweet_searches_data_path, 
                          "2.3-DubNtnStrngthNmbrs-2018-06-09-21-39-28.rds"))
DubTweetsGame3 <- read_rds(paste0(tweet_searches_data_path, 
                                      "2.3-DubTweetsGame3-2018-06-06.rds"))
TweetsDubNtnStrngthNmbrs <- read_rds(paste0(tweet_searches_data_path, 
                    "2.3-TweetsDubNtnStrngthNmbrs-2018-06-09-22-04-30.rds"))
UsersDubNtnStrngthNmbrs <- read_rds(paste0(tweet_searches_data_path, 
                    "2.3-UsersDubNtnStrngthNmbrs-2018-06-09-21-46-45.rds"))
```


# Motivation

This post will walk you through 1) collecting data from a Twitter API using the `rtweet` package, 2) creating a map with the tweets using the `ggmap`, `maps`, and `mapdata`, and 3) graphing the tweets with   You can find excellent documentation on the package [website](http://rtweet.info/), I am just going to go into more detail. 

## Set up the twitter app (with `rtweet`)

Install/load the package

```{r packages, message=FALSE, warning=FALSE}
library(tidyverse)
library(rtweet)
library(ggplot2)
library(ggmap)
library(maps)
library(mapdata)
library(gganimate)
library(ggraph)
library(igraph)
library(hrbrthemes)
library(ggalt)   
library(ggthemes) 
```


This is the first step for collecting tweets based on location. See the vignette [here](http://rtweet.info/articles/auth.html). I've outlined this process in the link below. 

![rtweet_setup](./Images/rtweet_setup.png)

## Searching for word occurances in tweets

We will start by collecting data on a certain hashtag occurrence. When I am writing this, it is game three of the NBA finals, so I will search for the hastag `#DubNation`. The function for collecting tweets is `rtweet::search_tweets()`, and it takes a query `q` (our term). 

Learn more about this function by typing:

```{r search_tweets_info}
# ?search_tweets
```

We will use all the default settings in this inital search. 

```{r search_tweets_DubTweets, eval=FALSE}
# tweets containing #DubNation
DubTweetsGame3 <- search_tweets("#DubNation")
```

After the `rtweet::search_tweets()` function has run, I will take a look at this data frame with `dplyr::glimpse()` 

```{r DubTweetsGame3_glimpse, eval=TRUE}
DubTweetsGame3 %>% dplyr::glimpse(78)
```

This data set contains `15,004` observations. If I want more tweets, I need to adjust the cap on the number of tweets I can collect with my API. I can do this by setting the `retryonratelimit` to `TRUE`.

See below from the manual:

> Logical indicating whether to wait and retry when rate limited. This argument is only relevant if the desired return (`n`) exceeds the remaining limit of available requests (assuming no other searches have been conducted in the past 15 minutes, this limit is 18,000 tweets). Defaults to false. Set to `TRUE` to automate process of conducting big searches (i.e., `n > 18000`). For many search queries, esp. specific or specialized searches, there wonâ€™t be more than 18,000 tweets to return. But for broad, generic, or popular topics, the total number of tweets within the `REST` window of time (7-10 days) can easily reach the millions.

## Collect data for `#DubNation` and `#StrengthInNumbers` with `rtweet::search_tweets2()`

The `rtweet::search_tweets2()` function works just like the `rtweet::search_tweets()`, but also "***returns data from one OR MORE search queries.***" 

I'll use `rtweet::search_tweets2()` to collect data for two hashtags now, `#DubNation` and `#StrengthInNumbers`, but set the `n` to `50000` and the `retryonratelimit` argument to `TRUE`. 

## Collect data for `#DubNation` and `#StrengthInNumbers` with `rtweet::search_tweets2()`

The `rtweet::search_tweets2()` function works just like the `rtweet::search_tweets()`, but also "***returns data from one OR MORE search queries.***" 

I'll use `rtweet::search_tweets2()` to collect data for two hashtags now, `#DubNation` and `#StrengthInNumbers`, but set the `n` to `50000` and the `retryonratelimit` argument to `TRUE`. 

```{r search_tweets2, eval=FALSE}
## search using multilple queries
DubNtnStrngthNmbrs <- rtweet::search_tweets2(
            c("\"#DubNation\"", 
              "#StrengthInNumbers"), 
            n = 50000, retryonratelimit = TRUE)
```

The structure for this data frame is displayed below with `dplyr::glimpse()`

```{r DubNtnStrngthNmbrs_glimpse, eval=TRUE}
DubNtnStrngthNmbrs %>% dplyr::glimpse(78)
```

This data frame has `56,966` observations, and adds one additional variable. We can use the handy `base::setdiff()` to figure out what variables are in `DubNtnStrngthNmbrs` that aren't in `DubTweetsGame3`.

```{r setdiff, eval=TRUE}
base::setdiff(x = names(DubNtnStrngthNmbrs),
              y = names(DubTweetsGame3))
```

The `query` variable contains our two search terms. 

```{r count_query, eval=TRUE}
DubNtnStrngthNmbrs %>% count(query)
```


### Get user data with `rtweet::users_data()`

The previous data frame had 87 variables in it, which includes the variables on users and tweets. We can use the `rtweet::users_data()` function to remove the users variables. 

The `base::intersect()` function allows us to see what variables from `DubNtnStrngthNmbrs` will end up in the results from `rtweet::users_data()`.

*I added `tibble::as_tibble()` so the variables print nicely to the screen.*  

```{r intersect_users_data, eval=TRUE}
tibble::as_tibble(base::intersect(x = base::names(DubNtnStrngthNmbrs),
                y = base::names(rtweet::users_data(DubNtnStrngthNmbrs))))
```


I'll store the contents in a new data frame called `UsersDubNtnStrngthNmbrs`.

```{r UsersDubNtnStrngthNmbrs, eval=TRUE}
# get user data 
UsersDubNtnStrngthNmbrs <- rtweet::users_data(DubNtnStrngthNmbrs)
UsersDubNtnStrngthNmbrs %>% glimpse(78)
```

## Get tweet data with `rtweet::tweets_data()`

I can also create another data frame with the tweet information using the `rtweet::tweets_data()` function. Just like above, I will display the variables in this new data frame (but limit it to the top 20).

I will store these variables in the `TweetsDubNtnStrngthNmbrs` data frame. 

```{r tweets_data, eval=TRUE}
tibble::as_tibble(
    intersect(x = base::names(DubNtnStrngthNmbrs),
          y = base::names(rtweet::tweets_data(DubNtnStrngthNmbrs)))) %>% 
          utils::head(20)
TweetsDubNtnStrngthNmbrs <- rtweet::tweets_data(DubNtnStrngthNmbrs)
```

### View the tweets in the `text` column 

The tweets are stored in the column/variable called `text`. We can review the first 10 of these entries with `dplyr::select()` and `utils::head()`.

```{r head_text, eval=TRUE}
DubNtnStrngthNmbrs %>% 
    dplyr::select(text) %>% 
    utils::head(10)
```

## The timeline of tweets with `rtweet::ts_plot()`

The `rtweet` package also comes with a handy function for plotting tweets over time with `rtweet::ts_plot()`. I added the `ggthemes::theme_gdocs()` theme and made the title text bold with `ggplot2::theme(plot.title = ggplot2::element_text())`.

```{r gg_ts_plot, message=FALSE, warning=FALSE, eval=TRUE, fig.height=4, fig.width=6.5}
gg_ts_plot <- DubNtnStrngthNmbrs %>% 
    rtweet::ts_plot(., by = "15 minutes") +
    ggthemes::theme_gdocs() +
    ggplot2::theme(plot.title = 
                       ggplot2::element_text(face = "bold")) +
    ggplot2::labs(
            x = NULL, 
            y = NULL,
            title = "#DubNation & #StrengthInNumbers tweets",
            caption = "\nSource: Counts aggregated using fifteen-minute intervals; 
                        data collected using Twitter's REST API via rtweet")
gg_ts_plot
ggsave(filename = "Images/gg_ts_plot.png", width = 6.5, height = 4, units = "in")
```

This graph shows an increase in tweets for these hashtags between `June 09, 12:00` to `June 09, 18:00`.

## Get longitude and lattitude for tweets in `DubTweets`

I can also add some geographic information to the twitter data (i.e. the latitude and longitude for each tweet) using the `rtweet::lat_lng()` function. 

This function adds a `lat` and `lng` variable to the `DubNtnStrngthNmbrs` data frame.  

*I verify this with `names()` and `tail()`*.

```{r DubNtnStrngthNmbrsLoc, eval=TRUE}
# get lattitude and longitude 
DubNtnStrngthNmbrsLoc <- rtweet::lat_lng(DubNtnStrngthNmbrs)
DubNtnStrngthNmbrs %>% names() %>% tail(2) 
DubNtnStrngthNmbrsLoc %>% names() %>% tail(2) 
```

I will check how many of the tweets have latitude and longitude information using `dplyr::distinct()` and `base::nrow()`.

```{r distinct_lat_lng_nrow, eval=TRUE}
DubNtnStrngthNmbrsLoc %>% dplyr::distinct(lng) %>% base::nrow()
DubNtnStrngthNmbrsLoc %>% dplyr::distinct(lat) %>% base::nrow()
```

Not every tweet has geographic information associated with it, so we will not be graphing all `56,966` observations. I'll rename `lng` to `long` so it will be easier to join to the state-level data. 

```{r rename_lng, eval=TRUE}
DubNtnStrngthNmbrsLoc <- DubNtnStrngthNmbrsLoc %>% dplyr::rename(long = lng)
```

## Create World Map of #DubNation/#StrengthInNumbers

I will use the `ggplot2::map_data()` function to get the `"world"` data I'll build a map with (save this as `World`).

```{r World, eval=TRUE}
library(maps)
library(mapdata)
World <- ggplot2::map_data("world")
World %>% glimpse(78)
```

The `ggplot2::geom_polygon()` function will create a map with the `World` data. The variables that build the map are `long` and `lat` (you can see why I renamed the `lng` variable to `long` in `DubNtnStrngthNmbrsLoc`). I added the Warrior team colors with `fill` and `color`.

```{r ggWorldMap, message=FALSE, warning=FALSE, eval=TRUE, fig.height=4, fig.width=6.5}
ggWorldMap <- ggplot2::ggplot() + 
    ggplot2::geom_polygon(data = World, 
                            aes(x = long, 
                                y = lat, 
                                group = group), 
                                fill = "gold", 
                                color = "royalblue",
                                alpha = 0.6) 
ggWorldMap + 
     ggplot2::theme(plot.title = ggplot2::element_text(face = "bold")) + 
     ggplot2::labs(title = "Basic World Map (geom_polygon)")
ggsave(filename = "Images/ggWorldMap.png", 
       width = 6.5, 
       height = 4, 
       units = "in")
```

## Add the tweet data to the map

Now that I have a basic projection of the world, I can layer the twitter data onto the map with `ggplot2::geom_point()` by specifying the `long` and `lat` to `x` and `y`. The `data` argument also needs to be specified because we will be introducing a second data set (and will not be using the `World` data).

This is what's referred to as the `mercator` projection. It is the default setting in `coord_quickmap()`. I also add the `ggthemes::theme_map()` for a cleaner print of the map (without ticks and axes)

```{r gg_mercator_dubstrngth, message=FALSE, warning=FALSE, eval=TRUE, fig.height=4, fig.width=6.5}
gg_Merc_title <- "  Worldwide (Mercator) #DubNation and #StrengthInNumbers tweets"
gg_Merc_cap <- "tweets collected with rtweet the hashtags #DubNation and #StrengthInNumbers"
gg_mercator_dubstrngth <- ggWorldMap + 
    ggplot2::coord_quickmap() +
        ggplot2::geom_point(data = DubNtnStrngthNmbrsLoc, 
                        aes(x = long, y = lat), 
                        size = 0.7, # reduce size of points
                        color = "firebrick") +
    # add titles/labels
     ggplot2::theme(plot.title = ggplot2::element_text(face = "bold")) + 
        ggplot2::labs(title = gg_Merc_title, 
        caption = gg_Merc_cap) +
        ggthemes::theme_map() 
gg_mercator_dubstrngth
ggplot2::ggsave(filename = "Images/gg_mercator_dubstrngth.png", 
                width = 6.5, 
                height = 4, 
                units = "in")
```

The Mercator projection works well for navigation because the meridians are equally spaced (the grid lines that runs north and south), but the parallels (the lines that run east/west around) are not equally spaced. This causes a distortion in the land masses at both poles. The map above makes it look like Greenland is roughly 1/2 or 2/3 the size of Africa, when in reality Africa is 14x larger.

## Mapping with the Winkel tripel projection

An alternative to the Mercator projection is the [Winkel tripel](https://en.wikipedia.org/wiki/Winkel_tripel_projection) projection. This map attempts to correct the distortions in the Mercator map. 

This map gets added via the `ggalt::coord_proj()` function, which takes a projection argument from the `proj4` [package.](https://cran.r-project.org/web/packages/proj4/index.html) I add the Winkel tripel layer with `ggplot2::coord_proj("+proj=wintri")` below. 


```{r ggDubWinkelTrip, message=FALSE, warning=FALSE, eval=TRUE, fig.height=4, fig.width=6.5}
# convert query to factor (you'll see why later)
DubNtnStrngthNmbrsLoc$query <- factor(DubNtnStrngthNmbrsLoc$query, 
                          labels = c("#DubNation", "#StrengthInNumbers"))
# define titles 
ggDubWT_title <- "Worldwide (Winkel tripel) #DubNation &\n#StrengthInNumbers tweets"
ggDubWT_cap <- "tweets collected with rtweet the hashtags #DubNation and #StrengthInNumbers  "

#  create world map 
ggWorld2 <- ggplot2::ggplot() + 
    ggplot2::geom_map(data = World, map = World,
                    aes(x = long, 
                        y = lat, 
                        map_id = region),
                    size = 0.009,
                    fill = "gold", 
                    alpha = 0.4) 
        #  add the twiiter data layer
ggDubWinkelTrip <- ggWorld2 + 
    ggplot2::geom_point(data = DubNtnStrngthNmbrsLoc, 
            aes(x = long, 
                y = lat),   
                    color = "royalblue",
                    size = 0.4) +
        # add Winkel tripel layer
        ggalt::coord_proj("+proj=wintri") +
            ggplot2::theme(plot.title = ggplot2::element_text(
                                                face = "bold")) + 
            ggplot2::labs(
            title = ggDubWT_title, 
            caption = ggDubWT_cap) 
ggDubWinkelTrip
ggsave(filename = "Images/ggDubWinkelTrip.png", width = 6.5, height = 4, units = "in")
```

This map is an ok start, but I want to add some additional customization:

+ I'll start by adjusting the x axis manually with `ggplot2::scale_x_continuous()` (this gives a full 'globe' on the map),  
+ I add the FiveThiryEight theme from `ggthemes::theme_fivethirtyeight()`,  
+ Remove the `x` and `y` axis labels with two `ggplot2::theme()` statements,  
+ Finally, facet these maps by the query type (`#DubNation` or `#StrengthInNumbers`)  

```{r ggDubWinkelTripFacet, message=FALSE, warning=FALSE, eval=TRUE, fig.height=4, fig.width=6.5}
ggDubWinkelTripFacet <- ggDubWinkelTrip + 
    ggplot2::scale_x_continuous(limits = c(-200, 200)) +
     ggthemes::theme_fivethirtyeight() +
    ggplot2::theme(
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank()) +
    ggplot2::theme(
        axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
    ggplot2::labs(title = ggDubWT_title, 
        caption = ggDubWT_cap) +
    facet_wrap( ~ query)
ggDubWinkelTripFacet
ggsave(filename = "Images/ggDubWinkelTripFacet.png", 
       width = 6.5, 
       height = 4, 
       units = "in")
```

To learn more about maps check out [this document](https://pubs.usgs.gov/pp/1453/report.pdf) put out by the U.S. Geological Survey on map projections. The description provided in the show [West Wing](https://www.youtube.com/watch?v=vVX-PrBRtTY) covers some of the distortions in the Mercator map, and this video from [Vox](https://www.youtube.com/watch?v=kIID5FDi2JQ) does a great job illustrating the difficulties in rendering a sphere or globe on a 2-d surface. 

## Animate the timeline of tweets with `gganiamte`

`rtweet` can collect twitter data over a period of 7-10 days, but the data I have in `DubNtnStrngthNmbrsLoc` only ranges from `"2018-06-09 07:40:22 UTC"` until `"2018-06-10 02:36:31 UTC"`. 

I want to see the spread of the `#DubNation` and `#StrengthInNumbers` tweets across the globe, but I want to use the point `size` in this this animated map to indicate the number of followers associated with each tweet. `gganimate` is the ideal package for this because it works well with `ggplot2`. 

I can start by looking at the number of followers for each account (`followers_count`) on the observations with location information (`long` and `lat`). 

```{r followers_count, eval=TRUE}
DubNtnStrngthNmbrsLoc %>%
    # identify observations with complete location information
        dplyr::filter(!is.na(long) | 
                  !is.na(lat)) %>%
    # get the sorted count
    dplyr::select(followers_count, screen_name) %>% 
    # arrange these descending
    dplyr::arrange(desc(followers_count)) %>% head(10)
```

This looks like there are a few `screen_name`s with > 10000 followers. I can get a quick view of the distribution of this variable with `qplot()` 

```{r check_distribution_for_outliers, eval=TRUE, message=TRUE, warning=TRUE,  fig.height=4, fig.width=6.5}
gg_freqploy_title <- "Frequency of followers_count for #DubNation &\n#StrengthInNumbers tweets"
DubNtnStrngthNmbrsLoc %>% 
        # identify observations with complete location information
        dplyr::filter(!is.na(long) | 
                  !is.na(lat)) %>%
        ggplot2::qplot(x = followers_count, 
                       data = ., 
                       geom = "freqpoly") +
            ggplot2::theme(plot.title = ggplot2::element_text(
                                                face = "bold", size = 14)) + 
            ggplot2::labs(
            title = gg_freqploy_title, 
            caption = ggDubWT_cap) 
ggsave(filename = "Images/gg_freqpolyv1.2.png", 
       width = 6.5, 
       height = 4, 
       units = "in")
```

This long tail tells me that these outliers are skewing the distribution. I want to see what the distribution looks like without these extremely high counts of followers. 

```{r remove_outliers, eval=TRUE, message=TRUE, warning=TRUE, fig.height=4, fig.width=6.5}
DubNtnStrngthNmbrsLoc %>% 
    # remove observations without location information
    dplyr::filter(!is.na(long) | 
                  !is.na(lat)) %>% 
    # arrange data
    dplyr::arrange(desc(followers_count)) %>% 
    # remove followers with more than 10,000 followers
    dplyr::filter(followers_count < 10000) %>% 
        ggplot2::qplot(followers_count, 
                       data = ., 
                       geom = "freqpoly") +
            ggplot2::theme(plot.title = ggplot2::element_text(
                                                face = "bold", size = 12)) + 
            ggplot2::labs(
            title = gg_freqploy_title, 
            caption = ggDubWT_cap) 
ggsave(filename = "Images/gg_freqpolyv1.2.png", width = 6.5, height = 4, units = "in")
```

This still looks skewed, but now we can see more of a distribution of followers. The majority of the observations fall under 2500 followers, with a few reaching above 7500. I will remove the observations with more than 10,000 followers.

```{r DubAnimateData, eval=TRUE}
DubAnimateData <- DubNtnStrngthNmbrsLoc %>% 
    # remove observations without location information
    dplyr::filter(!is.na(long) | 
                  !is.na(lat)) %>% 
    # arrange data descending 
    dplyr::arrange(desc(followers_count)) %>% 
    # remove the follower_count that are above 10,000
    dplyr::filter(followers_count < 10000) %>% 
    # select only the variables we will be visualizing 
    dplyr::select(user_id,
                  status_id,
                  screen_name,
                  followers_count,
                  friends_count,
                  favourites_count,
                  created_at,
                  text,
                  long,
                  hashtags,
                  lat)
DubAnimateData %>% glimpse(78)
```

Great! Now I will create another static Winkel tripel map before animating it get an idea for what it will look like. I start with the `ggWorld2` base from above, then layer in the twitter data, this time specifying `size = followers_count` and `ggplot2::scale_size_continuous()`. The `range` is the number of different points, and the `breaks` are the cut-offs for each size.

I also remove the `x` and `y` axis labels, and add the `ggthemes::theme_hc()` for a crisp looking finish. 

```{r gg_themehc_v1.0, eval=TRUE, message=TRUE, warning=TRUE, fig.height=4, fig.width=6.5}
ggWorld2 +
  geom_point(aes(x = long, 
                 y = lat, 
                 size = followers_count),
             data = DubAnimateData, 
             color = "royalblue", alpha = .2) +
  ggplot2::scale_size_continuous(range = c(1, 6), 
                                breaks = c(500, 1000, 2000, 
                                           4000, 6000, 8000)) +
  labs(size = "Followers") + 
    ggalt::coord_proj("+proj=wintri") + 
    ggthemes::theme_hc() +
    ggplot2::theme(
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank()) +
    ggplot2::theme(
        axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) + 
    ggplot2::theme(plot.title = ggplot2::element_text(
                                face = "bold", size = 12)) + 
    ggplot2::labs(title = "#DubNation & #StrengthInNumbers",
                  subtitle = "tweets and followers")
ggsave(filename = "Images/gg_themehc_v1.0.png", width = 6.5, height = 4, units = "in")
```

 I learned a helpful tip from Daniela Vasquez over at [d4tagirl](https://d4tagirl.com/2017/05/how-to-plot-animated-maps-with-gganimate) to build two data frames to use for displaying the animation before and after the points start appearing. These are best built using dates just outside the range of the `created_at` field. 

```{r create_empty_data_frame, eval=TRUE, message=FALSE, warning=FALSE}
library(tibble)
library(lubridate)
# min(DubAnimateData$created_at) # "2018-06-09 07:43:46 UTC"
# max(DubAnimateData$created_at) # "2018-06-10 02:36:31 UTC"
# create data frame foe the beginning of the animation
EmptyAnimateDataBegin <- tibble(
        created_at = as_datetime("2018-06-09 07:43:46 UTC"),
        followers_count = 0, 
        long = 0, 
        lat = 0)
EmptyAnimateDataBegin
# create data frame for the end of the animation
EmptyAnimateDataEnd <- tibble(
  created_at = seq(as_datetime("2018-06-10 03:00:00 UTC"),
                   as_datetime("2018-06-10 04:00:00 UTC"),
                   by = "min"), 
                followers = 0, 
                long = 0, 
                lat = 0)
EmptyAnimateDataEnd
```

Now I can use these two data frames to add additional layers to the animation. `gganimate` takes a `frame` argument, which is the value we want the `followers_count` to change over time (`created_at`).

The `cumulative = TRUE` tells R to leave the point on the map after its been plotted. 

```{r DubMap, eval=FALSE, echo=TRUE}
DubMap <- ggWorld2 +
  geom_point(aes(x = long, 
                 y = lat, 
                 size = followers_count,
                 frame = created_at,
                 cumulative = TRUE),
             data = DubAnimateData, 
             color = "royalblue", 
             alpha = .2) +
    # transparent frame 1
  geom_point(aes(x = long, 
                y = lat, 
                size = followers, 
                frame = created_at,
                cumulative = TRUE),
                        data = ghost_points_ini, 
                        alpha = 0) +
    # transparent frame 2
  geom_point(aes(x = long, 
                y = lat, 
                size = followers, 
                frame = created_at,
                cumulative = TRUE),
                        data = ghost_points_fin, 
                        alpha = 0) +
  scale_size_continuous(range = c(1, 6), 
                        breaks = c(500, 1000, 2000, 4000, 6000, 8000)) +
  labs(size = 'Followers') + 
    ggalt::coord_proj("+proj=wintri") + 
    ggthemes::theme_hc() +
    ggplot2::theme(
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank()) +
    ggplot2::theme(
        axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) + 
    ggplot2::labs(title = "#DubNation & #StrengthInNumbers",
                  subtitle = "tweets and followers")
library(gganimate)
gganimate(DubMap, interval = .2, "DubMap.gif")
```


Now I have an animation that displays the tweets as they appeared in the two days following the NBA finals. 

## Export the data 

`rtweet` has a handy export function for these twitter data frames as .csv files. 

```{r export_data, eval=TRUE}
rtweet::write_as_csv(x = DubNtnStrngthNmbrsLoc,
                 file_name = "Data/Processed/DubNtnStrngthNmbrsLoc.csv")

rtweet::write_as_csv(x = DubNtnStrngthNmbrs,
                 file_name = "Data/Processed/DubNtnStrngthNmbrs.csv")

rtweet::write_as_csv(x = DubTweetsGame3,
                 file_name = "Data/Processed/DubTweetsGame3.csv")

rtweet::write_as_csv(x = DubAnimateData,
                 file_name = "Data/Processed/DubAnimateData.csv")

rtweet::write_as_csv(x = TweetsDubNtnStrngthNmbrs,
                 file_name = "Data/Processed/TweetsDubNtnStrngthNmbrs.csv")

rtweet::write_as_csv(x = UsersDubNtnStrngthNmbrs,
                 file_name = "Data/Processed/UsersDubNtnStrngthNmbrs.csv")
```

To learn more check out these awesome resources: 

1. [Computing for the Social Sciences](https://goo.gl/m7wA6r)
2. [Making Maps with R](https://goo.gl/h4EszF)
3. [socviz - chapter 7 - Draw maps](https://goo.gl/ibYJuJ)
4. [gganimate package](https://github.com/dgrtwo/gganimate)  
5. [twitter api object definitions](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/intro-to-tweet-json)











